#### kafka
环境中zookeepr集群地址：localhost:2181,localhost:2182,localhost:2183
环境中kafka集群地址：localhost:9092,localhost:9093,localhost:9094 


shell中执行如下命令从创建名为testTopic的topic
```shell
kafka-topics.sh --create --zookeeper localhost:2181,localhost:2182,localhost:2183 --replication-factor 3 --partitions 3 --topic testTopic
```
如下命令查看topic有没有创建成功
```shell
kafka-topics.sh --zookeeper localhost:2181,localhost:2182,localhost:2183 --describe --topic  testTopic
```
如下命令生产消息：
```shell
kafka-console-producer.sh --broker-list localhost:9092,localhost:9093,localhost:9094   --topic testTopic
```
如下命令消费消息：
```shell
kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094  --topic testTopic
```

#### kafka同步发送和异步发送
> 异步发送：Kafka的生产者异步发送指的是在发送消息到Kafka集群时,并不等待服务器的响应,而是继续发送下一个消息。
这样可以提高发送消息的吞吐量。

>同步发送：同步发送是发送后不再去马上准备下一条，而是等收到集群反馈的成功消息才准备下一条；在异步发送的基础上，
再调用一下 get()方法即可

#### 整合kafka
1、添加依赖
<!-- kafka依赖 -->
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>


2、配置kafka相关参数
根据环境配置kafka相关参数
```properties
#kafka集群地址
spring.kafka.bootstrap-servers=localhost:9092,localhost:9093,localhost:9094
#生产者配置
#系列化方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#重试次数
spring.kafka.producer.retries=3
#采用的ack机制
spring.kafka.producer.acks=1
#批量提交的数据大小 16kb
spring.kafka.producer.batch-size=16384
#生产者暂存数据的缓冲区大小
spring.kafka.producer.buffer-memory=33554432
#如果自定义了拦截器，则需要在此配置;多个拦截器用逗号分割，拦截顺序与定义一致
spring.kafka.producer.properties.interceptor.classes=com.qin.interceptor.CustomProducerInterceptor


#消费者配置
#是否自动提交偏移量
spring.kafka.consumer.enable-auto-commit=true
#消费消息后间隔多长时间提交偏移量
spring.kafka.consumer.auto-commit-interval=100
#默认的消费者组，代码中可以热键修改
spring.kafka.consumer.group-id=test
# earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
# latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
# none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=latest
#系列化方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
```


3、编写代码测试
直接在需要的地方注入即可使用
```java
 @Autowired
 private KafkaTemplate kafkaTemplate;
```


#### 自定义拦截器
1、实现ProducerInterceptor接口，重写其方法

2、配置文件中进行配置
```properties
spring.kafka.producer.properties.interceptor.classes=com.qin.interceptor.CustomProducerInterceptor
```
#### 自定义分区器
* 若发送消息时指定了分区（即自定义分区策略），则直接将消息append到指定分区；
* 若发送消息时未指定patition，但指定了key（kafka允许为每条消息设置一个key），则对key值进行hash计算，根据计算结果路由到指定分区，这种情况下可以保证同一个Key的所有消息都进入到相同的分区；
* patition 和 key 都未指定，则使用kafka默认的分区策略，轮询选出一个 patition；


1、实现Partitioner类并重写其方法
2、配置文件中进行配置
```properties
spring.kafka.producer.properties.partitioner.class=com.qin.partition.CustomProducerPartitioner
```